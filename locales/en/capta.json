{
  "Capta": "Capta",
  "Corpus": "Corpus",
  "Dubbio- dataset 2": "Doubt - dataset 2",
  "Spazio- dataset 2": "Space - dataset 2",
  "Spazio- dataset 3": "Space - dataset 3",
  "Forma- dataset 2": "Form - dataset 2",
  "Forma- dataset 3": "Form - dataset 3",
  "Strumenti per la raccolta dati": "Data collection tools",
  "paragrafo_capta_1": "<0>The datasets we compiled are the very foundation on which we built the Atlas’ visualizations. In this section we will give a description of the datasets themselves and information on the planning choices, the methods and the tools we used while compiling them.<br/>This section is titled <i>Capta</i> instead of <i>Data</i> in order to highlight a concept that strongly influenced our work and is commonly used in Digital Humanities, in its definition by Johanna Drucker:</0><1><i>Capta</i> is “taken” actively while <i>data</i> is assumed to be a “given” able to be recorded and observed. From this distinction, a world of differences arises. Humanistic inquiry acknowledges the situated, partial, and constitutive character of knowledge production, the recognition that knowledge is constructed, taken, not simply given as a natural representation of pre-existing fact. (<4>Drucker, 2011</4>)</1><p>In order to provide a visual representation of a phenomenon, it is necessary to go through a phase in which the phenomenon is transformed into numbers and tables: as with any translation, it is a process of choices and selections. The analyses presented in this Atlas are the result of a humanities-focused research: as such, the connection with processes that involve reading and interpreting, instead of simply applying a statistical algorithm, is particularly evident. In order to give space to the peculiarities of humanities-oriented analysis, we opted for an iterative design process in which the structures and visual translations of the datasets changed as the analysis evolved.</p><p>In this process, we adapted existing visual models and created new ones to highlight exceptions, lack of homogeneity and ties to other humanities-related fields of study that would be difficult to represent with traditional solutions.</p><4>The results of this process are presented below: the datasets, which are conceptually considered <i>capta</i> by the authors of the project, and the tools that made their compiling possible.</4>",
  "paragrafo_capta_2": "<0><p>To clearly understand this section, it is important to underline that:</p><1><0>the <i>body of work</i> is the ensemble of all texts;</0><1>the <i>text</i>  is the single story/volume identified by a <i>title</i>;</1><2>the <i>occurrence</i>  is the word or passage analysed as minimal unit in a dataset;</2><3>the length of a text can be calculated in number of <i>characters</i> or number of <i>words</i>;</3><4>the position of <i>occurrences</i> in a text is marked through the number of characters;</4><5>the position and length of the occurrences can be “normalised”, namely recalculated in percentage with respect to the total number of characters in the text.</5></1></0>",
  "Corpus-text": "<0><0>This dataset consists of two relational tables containing information on the texts selected for the project. The information comes from: a) the section <i>Note e notizie sui testi</i>, edited by Mario Barenghi, Bruno Falcetto and Claudio Milanini in the three volumes <i>Romanzi e racconti</i> (<i>RR</i>, I, 1242-1393; <i>RR</i>, II, 1309-1475; <i>RR</i>, III, 1195-1350); b) from the bibliography <i>Bibliografia di Italo Calvino</i> by Luca Baranelli (Pisa, Edizioni della Normale, 2007).</0><p>The first table contains a list of the titles of each text. Each title has:</p><2><0>identifier or <1>ID</1>;</0><1>length in <1>characters</1> and <4>words</4>;</1><2><0>genre</0>;</2><3><0>volume</0> of <i>RR</i> that contains the text;</3><4>name of the .txt file containing the digital copy of the text (only available for internal use).</4></2><3>The second table shows the publishing history of each text, listing its various publications (see <2>Flows of the Stories</2>). In this table, each text’s ID appears once for each publication, accompanied by:</3><4><0><0>where it was published</0> (e.g., the magazine «Il caffè letterario e satirico»);</0><1>publication<0> date</0>;</1><2><0>flag</0> (e.g., true/false) that identifies the first publication.</2></4><p>When the text was published as a novel or as part of a collection, the corresponding ID is also present.</p><6>All the visualizations in this project are based, directly or indirectly, on these datasets and we particularly recommend the consultation of <2>Exploring the corpus as a territory</2>.</6><7>The one exception is <2>The Archipelago of Names</2>, the only visualization that takes Calvino’s essays into account in order to give an overview of the author’s intellectual universe.</7></0>",
  "Data/Capta": "Data/Capta",
  "Saggi": "Essays",
  "Spazio- dataset 1": "Space - dataset 1",
  "Forma- dataset 1": "Form - dataset 1",
  "Dubbio- dataset 1": "Doubt - dataset 1",
  "dataset non ancora disponibile": "Dataset currently unavailable ",
  "Saggi-text": "<0><0>This dataset is based on the reworking and development of the information from the index of names of the <i>Saggi. 1945-1985</i> (edited by Mario Barenghi, II, Milano, Mondadori, 1995, pp. 3045-3076).<br/>A text recognition algorithm was applied on the index using Adobe Acrobat Reader. The text was consequently converted in .txt (plain text); errors and imprecisions were fixed with the help of regular expressions or through careful manual procedures.\nThe information contained in the text files was then structured through a number of specially crafted <15>scripts</15> in node.js.</0><p>Through this first processing of the data, we crafted a table that contains, for each name, the following information:</p><2><0>identifier or <1>ID</1>;</0><1><0>occurrence</0> (name and surname);</1><2><0>position in the text</0> (page or pages);</2><3><0>title</0> of the text in which the occurrence appears;</3><4><0>length</0> of the text (beginning and end pages).</4></2><3>Using this information as the source, we generated a links table that shows the simultaneous presence of names in the same essay, subsequently visualized in the form of a network graph in <2>The Archipelago of Names</2>.</3><4>In order to expand the visualization’s potential, we connected every name to a number of biographical information (date of birth and death, occupation, nationality, etc.) using the OpenRefine function for the connection to the corresponding Wikidata. In case of missing or imprecise information, it was manually corrected or modified.<br/>This information has not been converted into a visualization yet, but it allowed us to closely observe the world of linked open data and of collaboratively edited multilingual knowledge graphs, providing many potential research opportunities.</4></0>",
  "Dubbio- dataset 1-text": "<0><p>This dataset catalogues the presence in the body of work of the terms ‘nebbia’ (fog) and ‘cancellazione’ (erasure). It was measured by adding up the number of occurrences of ‘nebbia’, ‘cancellazione’ and, when present, synonyms. The data allowed us to also see the terms’ chronological distribution. Using the number of typographical characters as the unit of measurement, we calculated the proportion of the various semantic fields and their frequency with respect to the total number of characters in every text.</p><p>Each occurrence comes with the following information:</p><2><0><0>ID of the text</0> where the occurrence appears;</0><1><0>occurrence</0>;</1><2><0>lexical field</0> to which the occurrence belongs;</2><3><0>position</0> in the text (beginning and end characters);</3><4><0>text location</0> (<i>incipit</i>/<i>explicit</i>/-);</4><5><0>use</0> of the occurrence (abstract/concrete).</5></2><3>We used this dataset to create the visualization <2>Fog</2> and the In-depth analysis <5>The fog-effect</5>.</3></0>",
  "Dubbio- dataset 2-text": "<0><0>This dataset represents the spread of what we named dubitative text throughout the body of work. The necessary data was collected with the <2>Wanderer</2>, tool by highlighting the parts of the text involved in the dubitative process.</0><p>In the dataset, the collected information is structured as follows:</p><2><0><0>ID of the text</0> where the occurrence appears;</0><1><0>ID of the occurrence</0> of dubitative text;</1><2><0>occurrence</0> of dubitative text;</2><3><0>position</0> in the text (beginning and end characters);</3><4><0>category</0> (content/form/meaning);</4><5><0>style</0> (hesitation/reformulation/negation);</5><6><1>expressions</1>;</6><7><0>parentheses</0> in the dubitative text (true/false);</7><8><0>asides</0> in the dubitative text (true/false);</8><9><0>occurrence</0> of text object of doubt;</9><10><0>position</0> in the text (beginning and end characters);</10><11><0>parentheses</0> in the text object of doubt (true/false);</11><12><0>asides</0> in the text object of doubt (true/false);</12><13><0>dubitative text also object of doubt</0> (yes/no).</13></2><p>Through the dataset we can learn the amount, position, and functioning mode of the dubitative process inside of a text.</p><4>We used this dataset to create the visualizations titled <2>Doubting</2> and  <5>Erasure</5>, and the second- and third-stage In-depth analyses, titled <8>The novel-essay that doubts</8> and <11>Doubt and erasure</11>.</4></0>",
  "Spazio- dataset 1-text": "<0><0>This dataset collects all the setting locations in Calvino’s body of work. The locations were manually identified and classified, partly through the use of the <2>Explorer</2> tool.</0><p>Each occurrence comes with the following information:</p><2><0><0>ID</0> of the location;</0><1><0>ID of the text</0> where the occurrence appears;</1><2><0>occurrence</0>;</2><3><0>belonging to or dependence</0> on a different location explicitly mentioned;</3><4><0>scale</0>;</4><5><1>specific</1> location (true/false);</5><6><1>terrestrial</1> location (true/false);</6><7><1>invented</1> location (true/false/not given);</7><8><0>category</0> (unspecified cosmic/specific cosmic/specific terrestrial/unspecified terrestrial/invented terrestrial/no location);</8><9><0>context</0> (war/Ligurian nature/urban landscape/sea/factory/metropolis/no context).</9></2><3><i>Scale</i> refers to the qualitative description of a location’s dimension (e.g., landmark, municipality, nation). It wasn’t always possible to find an appropriate description, and for this reason it is a category that was only marginally utilised.</3><4>We used this dataset to create the visualizations titled <2>Locations</2> and <5>Transforming</5>, and the respective In-depth analyses: <8>The shape of invented geography</8> and <11>Cartography of the terrestrial locations</11>. The dataset of the latter, which only examines the specific terrestrial locations, utilises two additional sets of information: the <13>geographical coordinates</13> and the <16>classification of the narrated time</16> of the selected texts.</4></0>",
  "Spazio- dataset 2-text": "<0><p>This dataset represents a selection and, at the same time, an expansion of what previously described. A selection, because it examines only the specific and unspecified terrestrial locations in Calvino’s short stories. An expansion, because this dataset uses additional information together with the data previously listed:</p><1><0><1>type</1> of location (indoor space/outdoor space/means of transport);</0><1><1>movement</1> (true/false);</1><2> <1>direction of the movement</1> (forward/backward).</2></1><2>We used this dataset to create the visualization <2>Realism</2>.</2></0>",
  "Spazio- dataset 3-text": "<0><0>The short story <i>Paura sul sentiero</i> works as this dataset’s foundation, with the aim of transforming the story into a visual object.</0><p>The dataset collects all the words in the story in the order in which they appear. Each occurrence comes with the following information:</p><2><0><0>ID</0> of the occurrence;</0><1><0>occurrence</0>;</1><2><0>setting location</0>;</2><3><0>type of narrative sequence</0> (reality/imagination/contextualization);</3><4><0>geographical location</0> (true/false);</4><5><0>proper noun</0> (true/false);</5><6><0>noun</0> (true/false);</6><7><0>type of noun</0> (abstract/concrete);</7><8><0>semantic field</0> (war/nature/human body/other);</8><9><0>metaphor</0> (true/false);</9><10><0>simile</0> (true/false);</10><11><0>question-doubt</0> (true/false);</11><12><0>vision-desire</0> (true/false).</12></2><3>We used this dataset to create the In-depth analysis <1>Metamorphosis of reality: tracking down fear</1>.</3></0>",
  "Forma- dataset 1-text": "<0><p>This dataset registers the occurrences of listing structures in the corpus, collected with the Explorer tool.</p><p>Each occurrence comes with the following information:</p><2><0><0>ID of the text</0> where the occurrence appears; </0><1><0>occurrence</0>;</1><2><0>position</0> in the text (beginning and end characters);</2><3><0>category</0> (words/phrases/clauses/mixed);</3><4><0>number of characters</0> of the occurrence;</4><5><0>number of characters</0> of the text where the occurrence appears;</5><6><0>percentage</0> of the number of characters of the occurrence with respect to the total number of characters in the text.</6></2><3>We used this dataset to create the visualization <2>Lists</2> and the In-depth analysis <5>For a listing aesthetic</5>.</3></0>",
  "Forma- dataset 2-text": "<0><0>The starting point for the creation of this dataset were the volumes published by Calvino over the course of his life, so we excluded the scattered stories that were never gathered into collections.<br/>Each volume was divided in sequences and for each sequence (each identified with an ID) we highlighted the internal sequences, when present, in order to show the internal layers of motifs in the text. All the segments were then categorized based on the <i>sequence type</i> and distributed between three <i>layers</i>. Inside each layer, the <i>sequence type</i> specifies the content or structural layer of the single segments.</0><p>Each occurrence comes with the following information:</p><2><0><0>ID of the volume</0> where the occurrence appears;</0><1><0>ID</0> of the occurrence;</1><2><0>series of the sequence types</0> on the same line;</2><3><0>level 1</0>;</3><4><0>position</0> of the occurrence in the text (beginning and end characters);</4><5>sequence <0>type</0>;</5><6><0>level 2</0>;</6><7><0>position</0> in the text (beginning and end characters);</7><8>sequence <0>type</0>;</8><9><0>level 3</0>;</9><10><0>position</0> in the text (beginning and end characters);</10><11>sequence <0>type</0>;</11><12><0>level 4</0>;</12><13><0>position</0> in the text (beginning and end characters);</13><14>sequence <0>type</0>;</14><15><0>level 5</0>;</15><16><0>position</0> in the text (beginning and end characters);</16><17>sequence <0>type</0>.</17></2><3>We used this dataset to create the visualization <2>Combining</2> and the In-depth analysis <5>Building variety</5>.</3></0>",
  "Forma- dataset 3-text": "<0><0>This dataset represents, expands and reworks the previous one by extending the same analysis to all the texts in the corpus. Each text was divided in segments that reuse the categorisation by <i>sequence type</i> from the previous dataset, but abandon the levels structure in order to follow the linear succession of the plot (each segment ends as soon as a different segment is detected, regardless of a possible overlap or the presence of an internal sequence).</0><p>Each occurrence comes with the following information:</p><2><0><0>ID of the text</0> where the occurrence appears;</0><1><0>position</0> of the occurrence in the text (beginning and end characters);</1><2><0>number of characters</0> of the occurrence;</2><3><0>number of characters</0> of the text where the occurrence appears.</3></2><3>We used this dataset to create the visualization <2>Plot</2> and the In-depth analysis <5>Reading between the plots</5>.</3></0>",
  "Strumenti per la raccolta dati-text": "<0><0>We gathered the data in the form of annotations on the text made through specially crafted digital tools. The pre-existing annotation-making applications proved inadequate for our work for many reasons. Among them were the need to upload the text on third-party servers, problems of obsolescence and incompatibility, or a too-steep learning curve. In compliance with the work’s copyright, the tools we introduced solve the problem of improper distribution of content by using a client-side approach, as already happens with other applications widely used in the world of visualization (e.g., <5>RAWGraphs</5>).</0><br/><2>Explorer <2>🔭</2></2><p>Through this tool it is possible to highlight parts of the text, to find the position in characters of the highlighted text, to specify a number of properties based on a data schema defined by the researcher and, lastly, to export this information in tabular format.</p><p>To use this tool, it is necessary to upload two files:</p><5><0>a text file in .txt format on which to apply the annotations;</0><1>a file in .tsv format containing the pattern for data gathering.</1></5><p>The length of texts like novels or longer stories makes it impossible to complete the analysis in a single session. In these cases, it is possible to export the work and subsequently re-upload it to resume the interrupted work.</p><7><0>Tutorial and source code <1></1></0></7><8><0>Use the tool <1></1></0></8><br/><10>Wanderer <2>🔬</2></10><p>This tool is an evolution of the previous one, inheriting all its functions. In addition, with Wanderer it is possible to select simultaneously two portions of text and highlight a connection between them.</p><12><0>Tutorial and source code <1></1></0></12><13><0>Use the tool <1></1></0></13></0>",
  "lang": "en"
}